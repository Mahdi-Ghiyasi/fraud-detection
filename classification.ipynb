{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from imblearn.over_sampling import SMOTE, ADASYN, RandomOverSampler\n",
    "from imblearn.combine import SMOTEENN, SMOTETomek\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE, ADASYN, RandomOverSampler\n",
    "from imblearn.combine import SMOTEENN, SMOTETomek\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>172786.0</td>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>172787.0</td>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>24.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>67.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>172792.0</td>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>217.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time         V1         V2        V3        V4        V5  \\\n",
       "0            0.0  -1.359807  -0.072781  2.536347  1.378155 -0.338321   \n",
       "1            0.0   1.191857   0.266151  0.166480  0.448154  0.060018   \n",
       "2            1.0  -1.358354  -1.340163  1.773209  0.379780 -0.503198   \n",
       "3            1.0  -0.966272  -0.185226  1.792993 -0.863291 -0.010309   \n",
       "4            2.0  -1.158233   0.877737  1.548718  0.403034 -0.407193   \n",
       "...          ...        ...        ...       ...       ...       ...   \n",
       "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
       "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
       "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
       "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
       "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
       "\n",
       "              V6        V7        V8        V9  ...       V21       V22  \\\n",
       "0       0.462388  0.239599  0.098698  0.363787  ... -0.018307  0.277838   \n",
       "1      -0.082361 -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672   \n",
       "2       1.800499  0.791461  0.247676 -1.514654  ...  0.247998  0.771679   \n",
       "3       1.247203  0.237609  0.377436 -1.387024  ... -0.108300  0.005274   \n",
       "4       0.095921  0.592941 -0.270533  0.817739  ... -0.009431  0.798278   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "284802 -2.606837 -4.918215  7.305334  1.914428  ...  0.213454  0.111864   \n",
       "284803  1.058415  0.024330  0.294869  0.584800  ...  0.214205  0.924384   \n",
       "284804  3.031260 -0.296827  0.708417  0.432454  ...  0.232045  0.578229   \n",
       "284805  0.623708 -0.686180  0.679145  0.392087  ...  0.265245  0.800049   \n",
       "284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.261057  0.643078   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28  Amount  \\\n",
       "0      -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62   \n",
       "1       0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69   \n",
       "2       0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66   \n",
       "3      -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50   \n",
       "4      -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99   \n",
       "...          ...       ...       ...       ...       ...       ...     ...   \n",
       "284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77   \n",
       "284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79   \n",
       "284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88   \n",
       "284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00   \n",
       "284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00   \n",
       "\n",
       "        Class  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "284802      0  \n",
       "284803      0  \n",
       "284804      0  \n",
       "284805      0  \n",
       "284806      0  \n",
       "\n",
       "[284807 rows x 31 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('creditcard.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test = train_test_split(data, test_size=0.2, random_state=42, shuffle=True)\n",
    "data_train = data_train.reset_index(drop=True)\n",
    "data_test = data_test.reset_index(drop=True)\n",
    "\n",
    "X_test = data_test.drop(['Class'], axis=1)\n",
    "y_test = data_test['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count of each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of fraud cases:  394\n",
      "Number of non-fraud cases:  227451\n",
      "Percentage of fraud cases:  0.17292457591783889\n",
      "Percentage of non-fraud cases:  99.82707542408215\n"
     ]
    }
   ],
   "source": [
    "fraud = data_train[data_train['Class'] == 1].value_counts().sum()\n",
    "not_fraud = data_train[data_train['Class'] == 0].value_counts().sum()\n",
    "\n",
    "print ('Number of fraud cases: ', fraud)\n",
    "print ('Number of non-fraud cases: ', not_fraud)\n",
    "print ('Percentage of fraud cases: ', fraud/(fraud+not_fraud)*100)\n",
    "print ('Percentage of non-fraud cases: ', not_fraud/(fraud+not_fraud)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjkAAAHCCAYAAAANVtgqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAqPklEQVR4nO3deXRU5eH/8c8kkIQlk4CQDCmRVVYpYKgQUVtqJEBE0dgC5ShLgKIJFYJsimzKwWIREFkOtRq//UpF/BZUsIEYNoWwBcJWoKwGColsyQBCEpL7+6Mn98c0AQnbkCfv1zlzDnOfZ+48N8cx73PnzsRhWZYlAAAAw/h4ewEAAAB3ApEDAACMROQAAAAjETkAAMBIRA4AADASkQMAAIxE5AAAACMROQAAwEhEDgAAMBKRA8Box44dU0BAgNavX39Tjz969KgcDoeSkpJu78JuUEFBgcLDwzV37lyvPD9QnhE5ACRJhw4d0u9//3s1bNhQAQEBcjqd6tixo2bNmqVLly55e3mSpLlz55Y5NiZPnqz27durY8eOJcbWrFmj5557Ti6XS35+fgoJCVH37t3197///Tat+NZVrlxZiYmJmjJlii5fvuzt5QDlCpEDQMuXL1erVq302WefqXv37po9e7amTp2q+++/XyNHjtQrr7zi7SVKKnvknDp1Sh9//LGGDBlSYmzChAnq1KmTdu/erd///veaP3++Ro4cqQsXLig2NlYLFy68jSu/Nf3799fp06fvqTUB5UElby8AgHcdOXJEvXr1Ur169bRq1SrVqVPHHouPj9fBgwe1fPlyL67w5v3v//6vKlWqpO7du3ts//zzzzV58mQ9//zzWrhwoSpXrmyPjRw5UitWrFBBQcHdXu41BQcHq3PnzkpKStKAAQO8vRyg3OBMDlDBTZs2TRcuXNBf/vIXj8Ap1rhxY48zOVeuXNGbb76pRo0ayd/fX/Xr19drr72mvLw8j8c5HA5NnDixxP7q16+vfv362feTkpLkcDi0fv16JSYmqnbt2qpWrZqeffZZnTp1yuNxe/bs0dq1a+VwOORwOPSrX/3quse2dOlStW/fXtWrV/fY/sYbb6hmzZr68MMPPQKnWHR0tJ566qlr7nfnzp3q16+f/daey+XSgAEDdObMGY9558+f17Bhw1S/fn35+/srJCRETz75pLZt22bPOXDggGJjY+VyuRQQEKC6deuqV69eys3N9djXk08+qe+++05nz5697jED+P84kwNUcF999ZUaNmyoRx555IbmDxw4UB9//LGef/55jRgxQps2bdLUqVO1d+9eLVmy5KbXMXToUNWoUUMTJkzQ0aNHNXPmTCUkJGjRokWSpJkzZ2ro0KGqXr26Xn/9dUlSaGjoNfdXUFCgLVu26KWXXvLYfuDAAe3bt08DBgxQYGDgTa01JSVFhw8fVv/+/eVyubRnzx4tWLBAe/bs0caNG+VwOCRJQ4YM0eeff66EhAS1aNFCZ86c0Xfffae9e/fqoYceUn5+vqKjo5WXl6ehQ4fK5XLp3//+t5YtW6acnBwFBQXZzxkRESHLsrRhw4brBhiAq1gAKqzc3FxLkvXMM8/c0PyMjAxLkjVw4ECP7a+++qolyVq1apW9TZI1YcKEEvuoV6+e1bdvX/v+Rx99ZEmyoqKirKKiInv78OHDLV9fXysnJ8fe1rJlS+uXv/zlDa314MGDliRr9uzZHtu/+OILS5I1Y8aMG9rPkSNHLEnWRx99ZG/78ccfS8z729/+Zkmy1q1bZ28LCgqy4uPjr7nv7du3W5KsxYsX/+Q6Tpw4YUmy/vjHP97QugFYFm9XARWY2+2WpBs+o/H1119LkhITEz22jxgxQpJu6dqdwYMH22dAJOmxxx5TYWGhvv/++5vaX/FbRzVq1PDYXtZjLk2VKlXsf1++fFmnT59Whw4dJMnjrajg4GBt2rRJJ06cKHU/xWdqVqxYoR9//PG6z1l8HKdPn77pdQMVDZEDVGBOp1PSf64duRHff/+9fHx81LhxY4/tLpdLwcHBNx0kknT//fd73C/+pX7u3Lmb3qckWZblcb+sx1yas2fP6pVXXlFoaKiqVKmi2rVrq0GDBpLkcS3NtGnTtHv3boWHh+vhhx/WxIkTdfjwYXu8QYMGSkxM1AcffKBatWopOjpac+bMKXE9ztXHcXUIArg+IgeowJxOp8LCwrR79+4yPe5WftEWFhaWut3X17fU7f8dKTfqvvvuk1Qykpo1ayZJ2rVr103tV5J++9vf6s9//rOGDBmiv//971q5cqWSk5MlSUVFRR7zDh8+rNmzZyssLEzvvPOOWrZsqX/84x/2nOnTp2vnzp167bXXdOnSJf3hD39Qy5Ytdfz4cY/nLD6OWrVq3fS6gYqGyAEquKeeekqHDh1SWlraT86tV6+eioqKdODAAY/t2dnZysnJUb169extNWrUUE5Ojse8/Px8nTx58qbXWpa4uv/++1WlShUdOXLEY3uTJk3UtGlTffHFF7pw4UKZ13Du3DmlpqZqzJgxmjRpkp599lk9+eSTatiwYanz69Spo5dffllLly7VkSNHdN9992nKlCkec1q1aqVx48Zp3bp1+vbbb/Xvf/9b8+fP95hTfBzNmzcv85qBiorIASq4UaNGqVq1aho4cKCys7NLjB86dEizZs2SJHXr1k3Sfz7pdLV3331XkhQTE2Nva9SokdatW+cxb8GCBdc8k3MjqlWrViKcrqVy5cpq166dtm7dWmJs0qRJOnPmjAYOHKgrV66UGF+5cqWWLVtW6n6Lzzj99xmm//6ZFBYWlnjbKSQkRGFhYfbH7d1ud4nnb9WqlXx8fEp8JD89PV0Oh0ORkZGlrgtASXyEHKjgGjVqpIULF6pnz55q3ry5XnzxRT344IPKz8/Xhg0btHjxYvt7bVq3bq2+fftqwYIFysnJ0S9/+Utt3rxZH3/8sXr06KFOnTrZ+x04cKCGDBmi2NhYPfnkk9qxY4dWrFhxS2+3REREaN68eXrrrbfUuHFjhYSE6Ne//vU15z/zzDN6/fXX5Xa77WtxJKlnz57atWuXpkyZou3bt6t3796qV6+ezpw5o+TkZKWmpl7z24WdTqcef/xxTZs2TQUFBfrZz36mlStXljhjdP78edWtW1fPP/+8WrdurerVq+ubb77Rli1bNH36dEnSqlWrlJCQoN/85jdq0qSJrly5or/+9a/y9fVVbGysx/5SUlLUsWNH+204ADfAux/uAnCv+Ne//mUNGjTIql+/vuXn52cFBgZaHTt2tGbPnm1dvnzZnldQUGBNmjTJatCggVW5cmUrPDzcGjt2rMccy7KswsJCa/To0VatWrWsqlWrWtHR0dbBgwev+RHyLVu2eDx+9erVliRr9erV9rasrCwrJibGCgwMtCT95MfJs7OzrUqVKll//etfSx1PTU21nnnmGSskJMSqVKmSVbt2bat79+7WF198Yc8p7SPkx48ft5599lkrODjYCgoKsn7zm9/YH/Eu/th8Xl6eNXLkSKt169ZWYGCgVa1aNat169bW3Llz7f0cPnzYGjBggNWoUSMrICDAqlmzptWpUyfrm2++8VhnTk6O5efnZ33wwQfXPV4AnhyWdZNX9QFAORAXF6d//etf+vbbb729lJs2c+ZMTZs2TYcOHfL4+DqA6yNyABgtMzNTTZo0UWpqaql/ifxeV1BQoEaNGmnMmDF6+eWXvb0coFwhcgAAgJH4dBUAADASkQMAAIxE5AAAACMROQAAwEgV+ssAi4qKdOLECQUGBvJH7wAAKCcsy9L58+cVFhYmH59rn6+p0JFz4sQJhYeHe3sZAADgJhw7dkx169a95niFjpzAwEBJ//khXf2V7wAA4N7ldrsVHh5u/x6/lgodOcVvUTmdTiIHAIBy5qcuNeHCYwAAYCQiBwAAGInIAQAARiJyAACAkYgcAABgJCIHAAAYicgBAABGInIAAICRiBwAAGAkIgcAABiJyAEAAEYicgAAgJGIHAAAYCQiBwAAGInIAQAARqrk7QXAO+qPWe7tJeAuOvp2jLeXgLuI13fFwuv72jiTAwAAjETkAAAAIxE5AADASEQOAAAwEpEDAACMROQAAAAjETkAAMBIRA4AADASkQMAAIxE5AAAACMROQAAwEhEDgAAMBKRAwAAjETkAAAAIxE5AADASEQOAAAwEpEDAACMROQAAAAjETkAAMBIRA4AADASkQMAAIxE5AAAACMROQAAwEhEDgAAMBKRAwAAjFSmyJk6dap+8YtfKDAwUCEhIerRo4f279/vMefy5cuKj4/Xfffdp+rVqys2NlbZ2dkeczIzMxUTE6OqVasqJCREI0eO1JUrVzzmrFmzRg899JD8/f3VuHFjJSUllVjPnDlzVL9+fQUEBKh9+/bavHlzWQ4HAAAYrEyRs3btWsXHx2vjxo1KSUlRQUGBOnfurIsXL9pzhg8frq+++kqLFy/W2rVrdeLECT333HP2eGFhoWJiYpSfn68NGzbo448/VlJSksaPH2/POXLkiGJiYtSpUydlZGRo2LBhGjhwoFasWGHPWbRokRITEzVhwgRt27ZNrVu3VnR0tH744Ydb+XkAAABDOCzLsm72wadOnVJISIjWrl2rxx9/XLm5uapdu7YWLlyo559/XpK0b98+NW/eXGlpaerQoYP+8Y9/6KmnntKJEycUGhoqSZo/f75Gjx6tU6dOyc/PT6NHj9by5cu1e/du+7l69eqlnJwcJScnS5Lat2+vX/ziF3r//fclSUVFRQoPD9fQoUM1ZsyYG1q/2+1WUFCQcnNz5XQ6b/bHUC7VH7Pc20vAXXT07RhvLwF3Ea/viqUivr5v9Pf3LV2Tk5ubK0mqWbOmJCk9PV0FBQWKioqy5zRr1kz333+/0tLSJElpaWlq1aqVHTiSFB0dLbfbrT179thzrt5H8ZzifeTn5ys9Pd1jjo+Pj6Kiouw5AACgYqt0sw8sKirSsGHD1LFjRz344IOSpKysLPn5+Sk4ONhjbmhoqLKysuw5VwdO8Xjx2PXmuN1uXbp0SefOnVNhYWGpc/bt23fNNefl5SkvL8++73a7y3DEAACgPLnpMznx8fHavXu3Pv3009u5njtq6tSpCgoKsm/h4eHeXhIAALhDbipyEhIStGzZMq1evVp169a1t7tcLuXn5ysnJ8djfnZ2tlwulz3nvz9tVXz/p+Y4nU5VqVJFtWrVkq+vb6lzivdRmrFjxyo3N9e+HTt2rGwHDgAAyo0yRY5lWUpISNCSJUu0atUqNWjQwGM8IiJClStXVmpqqr1t//79yszMVGRkpCQpMjJSu3bt8vgUVEpKipxOp1q0aGHPuXofxXOK9+Hn56eIiAiPOUVFRUpNTbXnlMbf319Op9PjBgAAzFSma3Li4+O1cOFCffHFFwoMDLSvoQkKClKVKlUUFBSkuLg4JSYmqmbNmnI6nRo6dKgiIyPVoUMHSVLnzp3VokULvfDCC5o2bZqysrI0btw4xcfHy9/fX5I0ZMgQvf/++xo1apQGDBigVatW6bPPPtPy5f//EwOJiYnq27ev2rVrp4cfflgzZ87UxYsX1b9//9v1swEAAOVYmSJn3rx5kqRf/epXHts/+ugj9evXT5I0Y8YM+fj4KDY2Vnl5eYqOjtbcuXPtub6+vlq2bJleeuklRUZGqlq1aurbt68mT55sz2nQoIGWL1+u4cOHa9asWapbt64++OADRUdH23N69uypU6dOafz48crKylKbNm2UnJxc4mJkAABQMd3S9+SUd3xPDiqKivg9GhUZr++KpSK+vu/K9+QAAADcq4gcAABgJCIHAAAYicgBAABGInIAAICRiBwAAGAkIgcAABiJyAEAAEYicgAAgJGIHAAAYCQiBwAAGInIAQAARiJyAACAkYgcAABgJCIHAAAYicgBAABGInIAAICRiBwAAGAkIgcAABiJyAEAAEYicgAAgJGIHAAAYCQiBwAAGInIAQAARiJyAACAkYgcAABgJCIHAAAYicgBAABGInIAAICRiBwAAGAkIgcAABiJyAEAAEYicgAAgJGIHAAAYCQiBwAAGInIAQAARiJyAACAkYgcAABgJCIHAAAYicgBAABGInIAAICRiBwAAGAkIgcAABiJyAEAAEYicgAAgJGIHAAAYCQiBwAAGInIAQAARiJyAACAkYgcAABgJCIHAAAYicgBAABGInIAAICRiBwAAGAkIgcAABiJyAEAAEYicgAAgJGIHAAAYCQiBwAAGInIAQAARiJyAACAkYgcAABgJCIHAAAYicgBAABGInIAAICRiBwAAGAkIgcAABiJyAEAAEYicgAAgJGIHAAAYKQyR866devUvXt3hYWFyeFwaOnSpR7j/fr1k8Ph8Lh16dLFY87Zs2fVp08fOZ1OBQcHKy4uThcuXPCYs3PnTj322GMKCAhQeHi4pk2bVmItixcvVrNmzRQQEKBWrVrp66+/LuvhAAAAQ5U5ci5evKjWrVtrzpw515zTpUsXnTx50r797W9/8xjv06eP9uzZo5SUFC1btkzr1q3T4MGD7XG3263OnTurXr16Sk9P1zvvvKOJEydqwYIF9pwNGzaod+/eiouL0/bt29WjRw/16NFDu3fvLushAQAAA1Uq6wO6du2qrl27XneOv7+/XC5XqWN79+5VcnKytmzZonbt2kmSZs+erW7duulPf/qTwsLC9Mknnyg/P18ffvih/Pz81LJlS2VkZOjdd9+1Y2jWrFnq0qWLRo4cKUl68803lZKSovfff1/z588v62EBAADD3JFrctasWaOQkBA1bdpUL730ks6cOWOPpaWlKTg42A4cSYqKipKPj482bdpkz3n88cfl5+dnz4mOjtb+/ft17tw5e05UVJTH80ZHRystLe2a68rLy5Pb7fa4AQAAM932yOnSpYv+53/+R6mpqfrjH/+otWvXqmvXriosLJQkZWVlKSQkxOMxlSpVUs2aNZWVlWXPCQ0N9ZhTfP+n5hSPl2bq1KkKCgqyb+Hh4bd2sAAA4J5V5rerfkqvXr3sf7dq1Uo///nP1ahRI61Zs0ZPPPHE7X66Mhk7dqwSExPt+263m9ABAMBQd/wj5A0bNlStWrV08OBBSZLL5dIPP/zgMefKlSs6e/asfR2Py+VSdna2x5zi+z8151rXAkn/uVbI6XR63AAAgJnueOQcP35cZ86cUZ06dSRJkZGRysnJUXp6uj1n1apVKioqUvv27e0569atU0FBgT0nJSVFTZs2VY0aNew5qampHs+VkpKiyMjIO31IAACgHChz5Fy4cEEZGRnKyMiQJB05ckQZGRnKzMzUhQsXNHLkSG3cuFFHjx5VamqqnnnmGTVu3FjR0dGSpObNm6tLly4aNGiQNm/erPXr1yshIUG9evVSWFiYJOl3v/ud/Pz8FBcXpz179mjRokWaNWuWx1tNr7zyipKTkzV9+nTt27dPEydO1NatW5WQkHAbfiwAAKC8K3PkbN26VW3btlXbtm0lSYmJiWrbtq3Gjx8vX19f7dy5U08//bSaNGmiuLg4RURE6Ntvv5W/v7+9j08++UTNmjXTE088oW7duunRRx/1+A6coKAgrVy5UkeOHFFERIRGjBih8ePHe3yXziOPPKKFCxdqwYIFat26tT7//HMtXbpUDz744K38PAAAgCEclmVZ3l6Et7jdbgUFBSk3N7fCXZ9Tf8xyby8Bd9HRt2O8vQTcRby+K5aK+Pq+0d/f/O0qAABgJCIHAAAYicgBAABGInIAAICRiBwAAGAkIgcAABiJyAEAAEYicgAAgJGIHAAAYCQiBwAAGInIAQAARiJyAACAkYgcAABgJCIHAAAYicgBAABGInIAAICRiBwAAGAkIgcAABiJyAEAAEYicgAAgJGIHAAAYCQiBwAAGInIAQAARiJyAACAkYgcAABgJCIHAAAYicgBAABGInIAAICRiBwAAGAkIgcAABiJyAEAAEYicgAAgJGIHAAAYCQiBwAAGInIAQAARiJyAACAkYgcAABgJCIHAAAYicgBAABGInIAAICRiBwAAGAkIgcAABiJyAEAAEYicgAAgJGIHAAAYCQiBwAAGInIAQAARiJyAACAkYgcAABgJCIHAAAYicgBAABGInIAAICRiBwAAGAkIgcAABiJyAEAAEYicgAAgJGIHAAAYCQiBwAAGInIAQAARiJyAACAkYgcAABgJCIHAAAYicgBAABGInIAAICRiBwAAGAkIgcAABiJyAEAAEYicgAAgJGIHAAAYKQyR866devUvXt3hYWFyeFwaOnSpR7jlmVp/PjxqlOnjqpUqaKoqCgdOHDAY87Zs2fVp08fOZ1OBQcHKy4uThcuXPCYs3PnTj322GMKCAhQeHi4pk2bVmItixcvVrNmzRQQEKBWrVrp66+/LuvhAAAAQ5U5ci5evKjWrVtrzpw5pY5PmzZN7733nubPn69NmzapWrVqio6O1uXLl+05ffr00Z49e5SSkqJly5Zp3bp1Gjx4sD3udrvVuXNn1atXT+np6XrnnXc0ceJELViwwJ6zYcMG9e7dW3Fxcdq+fbt69OihHj16aPfu3WU9JAAAYCCHZVnWTT/Y4dCSJUvUo0cPSf85ixMWFqYRI0bo1VdflSTl5uYqNDRUSUlJ6tWrl/bu3asWLVpoy5YtateunSQpOTlZ3bp10/HjxxUWFqZ58+bp9ddfV1ZWlvz8/CRJY8aM0dKlS7Vv3z5JUs+ePXXx4kUtW7bMXk+HDh3Upk0bzZ8//4bW73a7FRQUpNzcXDmdzpv9MZRL9ccs9/YScBcdfTvG20vAXcTru2KpiK/vG/39fVuvyTly5IiysrIUFRVlbwsKClL79u2VlpYmSUpLS1NwcLAdOJIUFRUlHx8fbdq0yZ7z+OOP24EjSdHR0dq/f7/OnTtnz7n6eYrnFD9PafLy8uR2uz1uAADATLc1crKysiRJoaGhHttDQ0PtsaysLIWEhHiMV6pUSTVr1vSYU9o+rn6Oa80pHi/N1KlTFRQUZN/Cw8PLeogAAKCcqFCfrho7dqxyc3Pt27Fjx7y9JAAAcIfc1shxuVySpOzsbI/t2dnZ9pjL5dIPP/zgMX7lyhWdPXvWY05p+7j6Oa41p3i8NP7+/nI6nR43AABgptsaOQ0aNJDL5VJqaqq9ze12a9OmTYqMjJQkRUZGKicnR+np6facVatWqaioSO3bt7fnrFu3TgUFBfaclJQUNW3aVDVq1LDnXP08xXOKnwcAAFRsZY6cCxcuKCMjQxkZGZL+c7FxRkaGMjMz5XA4NGzYML311lv68ssvtWvXLr344osKCwuzP4HVvHlzdenSRYMGDdLmzZu1fv16JSQkqFevXgoLC5Mk/e53v5Ofn5/i4uK0Z88eLVq0SLNmzVJiYqK9jldeeUXJycmaPn269u3bp4kTJ2rr1q1KSEi49Z8KAAAo9yqV9QFbt25Vp06d7PvF4dG3b18lJSVp1KhRunjxogYPHqycnBw9+uijSk5OVkBAgP2YTz75RAkJCXriiSfk4+Oj2NhYvffee/Z4UFCQVq5cqfj4eEVERKhWrVoaP368x3fpPPLII1q4cKHGjRun1157TQ888ICWLl2qBx988KZ+EAAAwCy39D055R3fk4OKoiJ+j0ZFxuu7YqmIr2+vfE8OAADAvYLIAQAARiJyAACAkYgcAABgJCIHAAAYicgBAABGInIAAICRiBwAAGAkIgcAABiJyAEAAEYicgAAgJGIHAAAYCQiBwAAGInIAQAARiJyAACAkYgcAABgJCIHAAAYicgBAABGInIAAICRiBwAAGAkIgcAABiJyAEAAEYicgAAgJGIHAAAYCQiBwAAGInIAQAARiJyAACAkYgcAABgJCIHAAAYicgBAABGInIAAICRiBwAAGAkIgcAABiJyAEAAEYicgAAgJGIHAAAYCQiBwAAGInIAQAARiJyAACAkYgcAABgJCIHAAAYicgBAABGInIAAICRiBwAAGAkIgcAABiJyAEAAEYicgAAgJGIHAAAYCQiBwAAGInIAQAARiJyAACAkYgcAABgJCIHAAAYicgBAABGInIAAICRiBwAAGAkIgcAABiJyAEAAEYicgAAgJGIHAAAYCQiBwAAGInIAQAARiJyAACAkYgcAABgJCIHAAAYicgBAABGInIAAICRiBwAAGAkIgcAABjptkfOxIkT5XA4PG7NmjWzxy9fvqz4+Hjdd999ql69umJjY5Wdne2xj8zMTMXExKhq1aoKCQnRyJEjdeXKFY85a9as0UMPPSR/f381btxYSUlJt/tQAABAOXZHzuS0bNlSJ0+etG/fffedPTZ8+HB99dVXWrx4sdauXasTJ07oueees8cLCwsVExOj/Px8bdiwQR9//LGSkpI0fvx4e86RI0cUExOjTp06KSMjQ8OGDdPAgQO1YsWKO3E4AACgHKp0R3ZaqZJcLleJ7bm5ufrLX/6ihQsX6te//rUk6aOPPlLz5s21ceNGdejQQStXrtQ///lPffPNNwoNDVWbNm305ptvavTo0Zo4caL8/Pw0f/58NWjQQNOnT5ckNW/eXN99951mzJih6OjoO3FIAACgnLkjZ3IOHDigsLAwNWzYUH369FFmZqYkKT09XQUFBYqKirLnNmvWTPfff7/S0tIkSWlpaWrVqpVCQ0PtOdHR0XK73dqzZ4895+p9FM8p3gcAAMBtP5PTvn17JSUlqWnTpjp58qQmTZqkxx57TLt371ZWVpb8/PwUHBzs8ZjQ0FBlZWVJkrKysjwCp3i8eOx6c9xuty5duqQqVaqUura8vDzl5eXZ991u9y0dKwAAuHfd9sjp2rWr/e+f//znat++verVq6fPPvvsmvFxt0ydOlWTJk3y6hoAAMDdccc/Qh4cHKwmTZro4MGDcrlcys/PV05Ojsec7Oxs+xoel8tV4tNWxfd/ao7T6bxuSI0dO1a5ubn27dixY7d6eAAA4B51xyPnwoULOnTokOrUqaOIiAhVrlxZqamp9vj+/fuVmZmpyMhISVJkZKR27dqlH374wZ6TkpIip9OpFi1a2HOu3kfxnOJ9XIu/v7+cTqfHDQAAmOm2R86rr76qtWvX6ujRo9qwYYOeffZZ+fr6qnfv3goKClJcXJwSExO1evVqpaenq3///oqMjFSHDh0kSZ07d1aLFi30wgsvaMeOHVqxYoXGjRun+Ph4+fv7S5KGDBmiw4cPa9SoUdq3b5/mzp2rzz77TMOHD7/dhwMAAMqp235NzvHjx9W7d2+dOXNGtWvX1qOPPqqNGzeqdu3akqQZM2bIx8dHsbGxysvLU3R0tObOnWs/3tfXV8uWLdNLL72kyMhIVatWTX379tXkyZPtOQ0aNNDy5cs1fPhwzZo1S3Xr1tUHH3zAx8cBAIDNYVmW5e1FeIvb7VZQUJByc3Mr3FtX9ccs9/YScBcdfTvG20vAXcTru2KpiK/vG/39zd+uAgAARiJyAACAkYgcAABgJCIHAAAYicgBAABGInIAAICRiBwAAGAkIgcAABiJyAEAAEYicgAAgJGIHAAAYCQiBwAAGInIAQAARiJyAACAkYgcAABgJCIHAAAYicgBAABGInIAAICRiBwAAGAkIgcAABiJyAEAAEYicgAAgJGIHAAAYCQiBwAAGInIAQAARiJyAACAkYgcAABgJCIHAAAYicgBAABGInIAAICRiBwAAGAkIgcAABiJyAEAAEYicgAAgJGIHAAAYCQiBwAAGInIAQAARiJyAACAkYgcAABgJCIHAAAYicgBAABGInIAAICRiBwAAGAkIgcAABiJyAEAAEYicgAAgJGIHAAAYCQiBwAAGInIAQAARiJyAACAkYgcAABgJCIHAAAYicgBAABGInIAAICRiBwAAGAkIgcAABiJyAEAAEYicgAAgJGIHAAAYCQiBwAAGInIAQAARiJyAACAkYgcAABgJCIHAAAYicgBAABGInIAAICRiBwAAGAkIgcAABiJyAEAAEYq95EzZ84c1a9fXwEBAWrfvr02b97s7SUBAIB7QLmOnEWLFikxMVETJkzQtm3b1Lp1a0VHR+uHH37w9tIAAICXlevIeffddzVo0CD1799fLVq00Pz581W1alV9+OGH3l4aAADwsnIbOfn5+UpPT1dUVJS9zcfHR1FRUUpLS/PiygAAwL2gkrcXcLNOnz6twsJChYaGemwPDQ3Vvn37Sn1MXl6e8vLy7Pu5ubmSJLfbfecWeo8qyvvR20vAXVQR/xuvyHh9VywV8fVdfMyWZV13XrmNnJsxdepUTZo0qcT28PBwL6wGuHuCZnp7BQDulIr8+j5//ryCgoKuOV5uI6dWrVry9fVVdna2x/bs7Gy5XK5SHzN27FglJiba94uKinT27Fndd999cjgcd3S98D63263w8HAdO3ZMTqfT28sBcBvx+q5YLMvS+fPnFRYWdt155TZy/Pz8FBERodTUVPXo0UPSf6IlNTVVCQkJpT7G399f/v7+HtuCg4Pv8Epxr3E6nfxPEDAUr++K43pncIqV28iRpMTERPXt21ft2rXTww8/rJkzZ+rixYvq37+/t5cGAAC8rFxHTs+ePXXq1CmNHz9eWVlZatOmjZKTk0tcjAwAACqech05kpSQkHDNt6eAq/n7+2vChAkl3rIEUP7x+kZpHNZPff4KAACgHCq3XwYIAABwPUQOAAAwEpEDAACMROQAAAAjlftPVwGlOX36tD788EOlpaUpKytLkuRyufTII4+oX79+ql27tpdXCAC40/h0FYyzZcsWRUdHq2rVqoqKirK/Nyk7O1upqan68ccftWLFCrVr187LKwUA3ElEDozToUMHtW7dWvPnzy/xN8ksy9KQIUO0c+dOpaWleWmFAO6kY8eOacKECfrwww+9vRR4GZED41SpUkXbt29Xs2bNSh3ft2+f2rZtq0uXLt3llQG4G3bs2KGHHnpIhYWF3l4KvIxrcmAcl8ulzZs3XzNyNm/ezJ/+AMqxL7/88rrjhw8fvksrwb2OyIFxXn31VQ0ePFjp6el64oknSlyT8+c//1l/+tOfvLxKADerR48ecjgcut4bEf/9VjUqJt6ugpEWLVqkGTNmKD093T5l7evrq4iICCUmJuq3v/2tl1cI4Gb97Gc/09y5c/XMM8+UOp6RkaGIiAjergKRA7MVFBTo9OnTkqRatWqpcuXKXl4RgFv19NNPq02bNpo8eXKp4zt27FDbtm1VVFR0l1eGew1vV8FolStXVp06dby9DAC30ciRI3Xx4sVrjjdu3FirV6++iyvCvYozOQAAwEj8WQcAAGAkIgcAABiJyAEAAEYicgCUWw6HQ0uXLvX2MgDco4gcAPesrKwsDR06VA0bNpS/v7/Cw8PVvXt3paamentpAMoBPkIO4J509OhRdezYUcHBwXrnnXfUqlUrFRQUaMWKFYqPj9e+ffu8vUQA9zjO5AC4J7388styOBzavHmzYmNj1aRJE7Vs2VKJiYnauHFjqY8ZPXq0mjRpoqpVq6phw4Z64403VFBQYI/v2LFDnTp1UmBgoJxOpyIiIrR161ZJ0vfff6/u3burRo0aqlatmlq2bKmvv/76rhwrgDuDMzkA7jlnz55VcnKypkyZomrVqpUYDw4OLvVxgYGBSkpKUlhYmHbt2qVBgwYpMDBQo0aNkiT16dNHbdu21bx58+Tr66uMjAz7W7Dj4+OVn5+vdevWqVq1avrnP/+p6tWr37FjBHDnETkA7jkHDx6UZVnX/Evy1zJu3Dj73/Xr19err76qTz/91I6czMxMjRw50t7vAw88YM/PzMxUbGysWrVqJUlq2LDhrR4GAC/j7SoA95yb/SL2RYsWqWPHjnK5XKpevbrGjRunzMxMezwxMVEDBw5UVFSU3n77bR06dMge+8Mf/qC33npLHTt21IQJE7Rz585bPg4A3kXkALjnPPDAA3I4HGW6uDgtLU19+vRRt27dtGzZMm3fvl2vv/668vPz7TkTJ07Unj17FBMTo1WrVqlFixZasmSJJGngwIE6fPiwXnjhBe3atUvt2rXT7Nmzb/uxAbh7+NtVAO5JXbt21a5du7R///4S1+Xk5OQoODhYDodDS5YsUY8ePTR9+nTNnTvX4+zMwIED9fnnnysnJ6fU5+jdu7cuXryoL7/8ssTY2LFjtXz5cs7oAOUYZ3IA3JPmzJmjwsJCPfzww/q///s/HThwQHv37tV7772nyMjIEvMfeOABZWZm6tNPP9WhQ4f03nvv2WdpJOnSpUtKSEjQmjVr9P3332v9+vXasmWLmjdvLkkaNmyYVqxYoSNHjmjbtm1avXq1PQagfOLCYwD3pIYNG2rbtm2aMmWKRowYoZMnT6p27dqKiIjQvHnzSsx/+umnNXz4cCUkJCgvL08xMTF64403NHHiREmSr6+vzpw5oxdffFHZ2dmqVauWnnvuOU2aNEmSVFhYqPj4eB0/flxOp1NdunTRjBkz7uYhA7jNeLsKAAAYiberAACAkYgcAABgJCIHAAAYicgBAABGInIAAICRiBwAAGAkIgcAABiJyAEAAEYicgAAgJGIHAAAYCQiBwAAGInIAQAARvp/+byCECkIS0YAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "over = SMOTETomek(sampling_strategy=0.10)\n",
    "under = RandomUnderSampler(sampling_strategy=1)\n",
    "steps = [('1', over), ('0', under)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "\n",
    "X_train, y_train = pipeline.fit_resample(data_train.drop(['Class'], axis=1), data_train['Class'])\n",
    "X_train = pd.DataFrame(X_train, columns=data_train.drop(['Class'], axis=1).columns)\n",
    "y_train = pd.DataFrame(y_train, columns=['Class'])\n",
    "data_train = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "data_train['Class'].value_counts().plot(kind='bar', title='Count (Class)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data_train.reset_index(drop=True)\n",
    "X_train = data_train.drop(['Class'], axis=1)\n",
    "y_train = data_train['Class']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=SVC(), n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1, 10], &#x27;gamma&#x27;: [&#x27;scale&#x27;, 1, 10, &#x27;auto&#x27;],\n",
       "                         &#x27;kernel&#x27;: [&#x27;rbf&#x27;, &#x27;poly&#x27;, &#x27;linear&#x27;]},\n",
       "             scoring=&#x27;f1&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=SVC(), n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1, 10], &#x27;gamma&#x27;: [&#x27;scale&#x27;, 1, 10, &#x27;auto&#x27;],\n",
       "                         &#x27;kernel&#x27;: [&#x27;rbf&#x27;, &#x27;poly&#x27;, &#x27;linear&#x27;]},\n",
       "             scoring=&#x27;f1&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(), n_jobs=-1,\n",
       "             param_grid={'C': [0.1, 1, 10], 'gamma': ['scale', 1, 10, 'auto'],\n",
       "                         'kernel': ['rbf', 'poly', 'linear']},\n",
       "             scoring='f1', verbose=1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls=SVC()\n",
    "param = {\n",
    "    'kernel': ['rbf', 'poly', 'linear'],\n",
    "    'C': [ 0.1, 1, 10],\n",
    "    'gamma': ['scale', 1, 10, 'auto'],\n",
    "}\n",
    "grid_search = GridSearchCV(estimator=cls, param_grid=param, cv=5, scoring='f1', verbose=1, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29</td>\n",
       "      <td>0.1</td>\n",
       "      <td>scale</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.977971</td>\n",
       "      <td>0.001820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31</td>\n",
       "      <td>0.1</td>\n",
       "      <td>scale</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.976662</td>\n",
       "      <td>0.001902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>0.1</td>\n",
       "      <td>scale</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.978089</td>\n",
       "      <td>0.001725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.942350</td>\n",
       "      <td>0.002280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.996430</td>\n",
       "      <td>0.000489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.978089</td>\n",
       "      <td>0.001725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>36</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.281149</td>\n",
       "      <td>0.006869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.995773</td>\n",
       "      <td>0.000746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>25</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.978089</td>\n",
       "      <td>0.001725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>29</td>\n",
       "      <td>0.1</td>\n",
       "      <td>auto</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.977971</td>\n",
       "      <td>0.001820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>31</td>\n",
       "      <td>0.1</td>\n",
       "      <td>auto</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.976662</td>\n",
       "      <td>0.001902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>25</td>\n",
       "      <td>0.1</td>\n",
       "      <td>auto</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.978089</td>\n",
       "      <td>0.001725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>scale</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.989654</td>\n",
       "      <td>0.000973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>scale</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.985595</td>\n",
       "      <td>0.001072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>scale</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.980595</td>\n",
       "      <td>0.001497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.995371</td>\n",
       "      <td>0.001209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.996000</td>\n",
       "      <td>0.000524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.980595</td>\n",
       "      <td>0.001497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.932756</td>\n",
       "      <td>0.004454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.995773</td>\n",
       "      <td>0.000746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.980595</td>\n",
       "      <td>0.001497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>auto</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.989631</td>\n",
       "      <td>0.000946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>auto</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.985525</td>\n",
       "      <td>0.001065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>auto</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.980595</td>\n",
       "      <td>0.001497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>scale</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.995908</td>\n",
       "      <td>0.000714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>scale</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.994400</td>\n",
       "      <td>0.000663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>scale</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.981559</td>\n",
       "      <td>0.001629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.996129</td>\n",
       "      <td>0.001005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.995773</td>\n",
       "      <td>0.000746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.981559</td>\n",
       "      <td>0.001629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>33</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.943305</td>\n",
       "      <td>0.004449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.995773</td>\n",
       "      <td>0.000746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.981559</td>\n",
       "      <td>0.001629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>auto</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.995908</td>\n",
       "      <td>0.000714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>auto</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.994400</td>\n",
       "      <td>0.000663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>auto</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.981559</td>\n",
       "      <td>0.001629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rank_test_score param_C param_gamma param_kernel  mean_test_score  \\\n",
       "0                29     0.1       scale          rbf         0.977971   \n",
       "1                31     0.1       scale         poly         0.976662   \n",
       "2                25     0.1       scale       linear         0.978089   \n",
       "3                34     0.1           1          rbf         0.942350   \n",
       "4                 1     0.1           1         poly         0.996430   \n",
       "5                25     0.1           1       linear         0.978089   \n",
       "6                36     0.1          10          rbf         0.281149   \n",
       "7                 6     0.1          10         poly         0.995773   \n",
       "8                25     0.1          10       linear         0.978089   \n",
       "9                29     0.1        auto          rbf         0.977971   \n",
       "10               31     0.1        auto         poly         0.976662   \n",
       "11               25     0.1        auto       linear         0.978089   \n",
       "12               13       1       scale          rbf         0.989654   \n",
       "13               15       1       scale         poly         0.985595   \n",
       "14               21       1       scale       linear         0.980595   \n",
       "15               10       1           1          rbf         0.995371   \n",
       "16                3       1           1         poly         0.996000   \n",
       "17               21       1           1       linear         0.980595   \n",
       "18               35       1          10          rbf         0.932756   \n",
       "19                6       1          10         poly         0.995773   \n",
       "20               21       1          10       linear         0.980595   \n",
       "21               14       1        auto          rbf         0.989631   \n",
       "22               16       1        auto         poly         0.985525   \n",
       "23               21       1        auto       linear         0.980595   \n",
       "24                4      10       scale          rbf         0.995908   \n",
       "25               11      10       scale         poly         0.994400   \n",
       "26               17      10       scale       linear         0.981559   \n",
       "27                2      10           1          rbf         0.996129   \n",
       "28                6      10           1         poly         0.995773   \n",
       "29               17      10           1       linear         0.981559   \n",
       "30               33      10          10          rbf         0.943305   \n",
       "31                6      10          10         poly         0.995773   \n",
       "32               17      10          10       linear         0.981559   \n",
       "33                4      10        auto          rbf         0.995908   \n",
       "34               11      10        auto         poly         0.994400   \n",
       "35               17      10        auto       linear         0.981559   \n",
       "\n",
       "    std_test_score  \n",
       "0         0.001820  \n",
       "1         0.001902  \n",
       "2         0.001725  \n",
       "3         0.002280  \n",
       "4         0.000489  \n",
       "5         0.001725  \n",
       "6         0.006869  \n",
       "7         0.000746  \n",
       "8         0.001725  \n",
       "9         0.001820  \n",
       "10        0.001902  \n",
       "11        0.001725  \n",
       "12        0.000973  \n",
       "13        0.001072  \n",
       "14        0.001497  \n",
       "15        0.001209  \n",
       "16        0.000524  \n",
       "17        0.001497  \n",
       "18        0.004454  \n",
       "19        0.000746  \n",
       "20        0.001497  \n",
       "21        0.000946  \n",
       "22        0.001065  \n",
       "23        0.001497  \n",
       "24        0.000714  \n",
       "25        0.000663  \n",
       "26        0.001629  \n",
       "27        0.001005  \n",
       "28        0.000746  \n",
       "29        0.001629  \n",
       "30        0.004449  \n",
       "31        0.000746  \n",
       "32        0.001629  \n",
       "33        0.000714  \n",
       "34        0.000663  \n",
       "35        0.001629  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame(grid_search.cv_results_)\n",
    "result = result[['rank_test_score', 'param_C', 'param_gamma', 'param_kernel', 'mean_test_score', 'std_test_score']]\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OverSampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_train, data_test = train_test_split(data, test_size=0.2, random_state=42, shuffle=True)\n",
    "data_train = data_train.reset_index(drop=True)\n",
    "data_test = data_test.reset_index(drop=True)\n",
    "\n",
    "X_test = data_test.drop(['Class'], axis=1)\n",
    "y_test = data_test['Class']\n",
    "\n",
    "over = SMOTETomek(sampling_strategy=1)\n",
    "under = RandomUnderSampler(sampling_strategy=1)\n",
    "steps = [('1', over), ('0', under)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "\n",
    "X_train, y_train = pipeline.fit_resample(data_train.drop(['Class'], axis=1), data_train['Class'])\n",
    "X_train = pd.DataFrame(X_train, columns=data_train.drop(['Class'], axis=1).columns)\n",
    "y_train = pd.DataFrame(y_train, columns=['Class'])\n",
    "data_train = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "data_train['Class'].value_counts().plot(kind='bar', title='Count (Class)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data_train.reset_index(drop=True)\n",
    "X_train = data_train.drop(['Class'], axis=1)\n",
    "y_train = data_train['Class']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=0.1, gamma=1, kernel=&#x27;poly&#x27;, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=0.1, gamma=1, kernel=&#x27;poly&#x27;, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=0.1, gamma=1, kernel='poly', random_state=42)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm=SVC(kernel='poly', C=0.1, gamma=1, random_state=42)\n",
    "svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.53      0.80      0.64        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.77      0.90      0.82     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "[[56796    68]\n",
      " [   20    78]]\n",
      "Accuracy:  0.9984551104244935\n",
      "Precision:  0.5342465753424658\n",
      "Recall:  0.7959183673469388\n",
      "F1:  0.6393442622950819\n"
     ]
    }
   ],
   "source": [
    "y_pred = svm.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred))\n",
    "print('Recall: ', recall_score(y_test, y_pred))\n",
    "print('F1: ', f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LogisticRegression train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000, random_state=42, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000, random_state=42, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000, random_state=42, solver='liblinear')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lr = LogisticRegression(random_state=42, max_iter=1000, solver='liblinear')\n",
    "Lr.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     56864\n",
      "           1       0.16      0.90      0.27        98\n",
      "\n",
      "    accuracy                           0.99     56962\n",
      "   macro avg       0.58      0.94      0.63     56962\n",
      "weighted avg       1.00      0.99      0.99     56962\n",
      "\n",
      "[[56398   466]\n",
      " [   10    88]]\n",
      "Accuracy:  0.9916435518415786\n",
      "Precision:  0.1588447653429603\n",
      "Recall:  0.8979591836734694\n",
      "F1:  0.2699386503067485\n"
     ]
    }
   ],
   "source": [
    "y_pred = Lr.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred))\n",
    "print('Recall: ', recall_score(y_test, y_pred))\n",
    "print('F1: ', f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential Model train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "model1 = Sequential()\n",
    "model1.add(Dense(32, activation='relu', input_shape=X_train[0].shape))\n",
    "model1.add(Dense(16, activation='relu'))\n",
    "model1.add(Dense(8, activation='relu'))\n",
    "model1.add(Dense(1, activation='sigmoid'))\n",
    "model1.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.01), metrics=[f1_m])\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_20 (Dense)            (None, 32)                992       \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1665 (6.50 KB)\n",
      "Trainable params: 1665 (6.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5670/5670 [==============================] - 15s 3ms/step - loss: 0.0058 - f1_m: 0.9987 - val_loss: 0.0018 - val_f1_m: 0.9998\n",
      "Epoch 2/50\n",
      "5670/5670 [==============================] - 14s 2ms/step - loss: 0.0041 - f1_m: 0.9988 - val_loss: 3.6765e-04 - val_f1_m: 1.0000\n",
      "Epoch 3/50\n",
      "5670/5670 [==============================] - 17s 3ms/step - loss: 0.0061 - f1_m: 0.9988 - val_loss: 0.0022 - val_f1_m: 0.9997\n",
      "Epoch 4/50\n",
      "5670/5670 [==============================] - 15s 3ms/step - loss: 0.0041 - f1_m: 0.9992 - val_loss: 7.2010e-04 - val_f1_m: 0.9999\n",
      "Epoch 5/50\n",
      "5670/5670 [==============================] - 13s 2ms/step - loss: 0.0029 - f1_m: 0.9992 - val_loss: 5.4315e-04 - val_f1_m: 1.0000\n",
      "Epoch 6/50\n",
      "5670/5670 [==============================] - 12s 2ms/step - loss: 0.0043 - f1_m: 0.9990 - val_loss: 4.5620e-04 - val_f1_m: 1.0000\n",
      "Epoch 7/50\n",
      "5670/5670 [==============================] - 13s 2ms/step - loss: 0.0040 - f1_m: 0.9991 - val_loss: 0.0015 - val_f1_m: 0.9998\n"
     ]
    }
   ],
   "source": [
    "history1 = model1.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=64,\n",
    "    epochs=50,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1781/1781 [==============================] - 3s 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.71      0.81      0.75        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.85      0.90      0.88     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "[[56831    33]\n",
      " [   19    79]]\n",
      "Accuracy:  0.9990871107053826\n",
      "Precision:  0.7053571428571429\n",
      "Recall:  0.8061224489795918\n",
      "F1:  0.7523809523809524\n"
     ]
    }
   ],
   "source": [
    "y_pred1 = model1.predict(X_test)\n",
    "y_pred1 = np.round(y_pred1)\n",
    "y_pred1 = y_pred1.astype(int)\n",
    "print(classification_report(y_test, y_pred1))\n",
    "print(confusion_matrix(y_test, y_pred1))\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred1))\n",
    "print(\"Precision: \", precision_score(y_test, y_pred1))\n",
    "print(\"Recall: \", recall_score(y_test, y_pred1))\n",
    "print(\"F1: \", f1_score(y_test, y_pred1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.81      0.84      0.82        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.91      0.92      0.91     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "[[56845    19]\n",
      " [   16    82]]\n",
      "Accuracy:  0.999385555282469\n",
      "Precision:  0.8118811881188119\n",
      "Recall:  0.8367346938775511\n",
      "F1:  0.8241206030150754\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "y_pred = xgb.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision: \", precision_score(y_test, y_pred))\n",
    "print(\"Recall: \", recall_score(y_test, y_pred))\n",
    "print(\"F1: \", f1_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
